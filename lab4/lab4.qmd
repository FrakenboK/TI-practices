---
title: "Практическая работа №4. Исследование метаданных DNS трафика"
author: "kobyakmihail@yandex.ru"
format: 
  md:
    output-file: README.md
---

## Цель работы

1. Зекрепить практические навыки использования языка программирования R для обработки данных
2. Закрепить знания основных функций обработки данных экосистемы `tidyverse` языка R
3. Закрепить навыки исследования метаданных DNS трафика

## Исходные данные

1.  Программное обеспечение Windows 11
2.  Интерпретатор языка R v4.5.1
3.  Rstudio IDE

## Общая ситуация

Вы исследуете подозрительную сетевую активность во внутренней сети Доброй Организации. Вам в руки попали метаданные о DNS трафике в исследуемой сети. Исследуйте файлы, восстановите данные, подготовьте их к анализу и дайте обоснованные ответы на поставленные вопросы исследования.

## Задание 

Используя программный пакет `dplyr`, освоить анализ DNS логов с помощью языка программирования R.

## Подготовка к выполнению задания 

Произведем загрузку библиотек:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)

library(dplyr)

library(httr)
library(jsonlite)
```

## Шаги

### Подготовка данных

#### 1. Импортируйте данные DNS https://storage.yandexcloud.net/dataset.ctfsec/dns.zip

Произведем загрузку архива с лоагми. Загружать все данные будем в диркеторию `data` (ее нужно создать, если не существует):

```{r}
if (!dir.exists("data")) {
  dir.create("data")
}

file_url <- "https://storage.yandexcloud.net/dataset.ctfsec/dns.zip"
zip_filename <- "data/dns.zip"

download.file(
  url = file_url,
  destfile = zip_filename,
  mode = "wb",
  quiet = FALSE
)
```

Распакуем загруженный архив:

```{r}
unzip(zip_filename,  exdir = "data")
```

Загрузим данные из лога:

```{r}
dns_log <- read_delim("data/dns.log", 
                        delim = "\t",
                        col_names = FALSE,
                        col_types = cols(.default = col_character()),
                        trim_ws = TRUE,
                        na = c("", "NA", "-"))
dns_log
```

Видим, что в данных отсутствуют названия столбцов

#### 2. Добавьте пропущенные данные о структуре данных (назначении столбцов)

Обозначим названия столбцов:

```{r}
column_names <- c("timestamp", "uid", "src_ip", "src_port", "dst_ip", "dst_port",
                    "proto", "trans_id", "query", "qclass", "qclass_name", "qtype", 
                    "qtype_name", "rcode", "rcode_name", "AA", "TC", "RD", "RA", 
                    "Z", "answers", "TTLs", "rejected")
```

Еще раз загрузим данные из файла с логом, но на этот раз с названиями столбцов:

```{r}
dns_log <- read_delim("data/dns.log",
                        delim = "\t",
                        col_names = column_names,
                        col_types = cols(.default = col_character()),
                        trim_ws = TRUE,
                        na = c("", "NA", "-"))

dns_log
```

Видим, что в данных неправильно указаны типы данных для столбцов

#### 3. Преобразуйте данные в столбцах в нужный формат

Еще раз загрузим данные из файла с логом, но на этот раз зададим каждом столбцу название и тип. После загрузки преобразуем дату к формату `datetime` и информацию о флагах к типу `boolean`:

```{r}
dns_log <- read_delim("data/dns.log",
                        delim = "\t",
                        col_names = column_names,
                        col_types = cols(
                            timestamp = col_double(),

                            uid = col_character(),

                            src_ip = col_character(),
                            src_port = col_integer(),
                            dst_ip = col_character(),
                            dst_port = col_integer(),

                            proto = col_character(),
                            trans_id = col_integer(),

                            query = col_character(),

                            qclass = col_integer(),
                            qclass_name = col_character(),
                            qtype = col_integer(),
                            qtype_name = col_character(),

                            rcode = col_integer(),
                            rcode_name = col_character(),

                            AA = col_character(),
                            TC = col_character(),
                            RD = col_character(),
                            RA = col_character(),

                            Z = col_integer(),
                            answers = col_character(),
                            TTLs = col_character(),
                            rejected = col_character()
                        ),
                        trim_ws = TRUE,
                        na = c("", "NA", "-", "(empty)"))

dns_log <- dns_log %>%
    mutate(
        timestamp = as.POSIXct(timestamp, origin = "1970-01-01"),

        AA = AA == "T",
        TC = TC == "T",
        RD = RD == "T",
        RA = RA == "T",
        rejected = rejected == "T"
    )

dns_log
```

#### 4. Просмотрите общую структуру данных с помощью функции `glimpse`

```{r}
glimpse(dns_log)
```

### Анализ

#### 5. Сколько участников информационного обмена в сети Доброй Организации?

Воспользуемся `pivot_longer` из пакета `tidyverse`

```{r}
dns_log %>%
    pivot_longer(
        cols = c(src_ip, dst_ip), 
        values_to = "ip"
    ) %>%
    distinct(ip) %>%
    filter(!is.na(ip)) %>%
    count() %>%
    rename(ip_count = n)
```

#### 6. Какое соотношение участников обмена внутри сети и участников обращений к внешним ресурсам?

К приватным сетям IPv4 относятся следующие: `10.0.0.0/8`, `172.16.0.0/12` и `192.168.0.0/16`. Для решения задания воспользуемся регулярными выражениями:

```{r}
IPv4_regex <- "(^10\\.)|(^172\\.1[6-9]\\.)|(^172\\.2[0-9]\\.)|(^172\\.3[0-1]\\.)|(^192\\.168\\.)"

with(
    dns_log, 
    sum(!duplicated(c(
        src_ip[grepl(IPv4_regex, src_ip, perl = TRUE)],
        dst_ip[grepl(IPv4_regex, dst_ip, perl = TRUE)]
    ))) / sum(!duplicated(c(
        src_ip[!grepl(IPv4_regex, src_ip, perl = TRUE)],
        dst_ip[!grepl(IPv4_regex, dst_ip, perl = TRUE)]
    )))
)
```

#### 7. Найдите топ-10 участников сети, проявляющих наибольшую сетевую активность

Воспользуемся `pivot_longer` из пакета `tidyverse`. Посчитем, какие IP-адреса встречаются чаще всего:

```{r}
dns_log %>%
    pivot_longer(
        cols = c(src_ip, dst_ip), 
        values_to = "ip"
    ) %>%
    count(ip, name = "activity_count") %>%
    arrange(desc(activity_count)) %>%
    slice_head(n = 10)
```

#### 8. Найдите топ-10 доменов, к которым обращаются пользователи сети и соответственное количество обращений

```{r}
top_10_domains_list <- dns_log %>%
    count(query, name = "request_count") %>%
    arrange(
        desc(request_count)
    ) %>%
    slice_head(n = 10)

top_10_domains_list
```

#### 9. Опеределите базовые статистические характеристики (функция `summary()`) интервала времени между последовательными обращениями к топ-10 доменам.

```{r}
top_domains_log <- dns_log %>%
    filter(query %in% top_10_domains_list$query) %>%
    arrange(query, timestamp)

time_intervals <- top_domains_log %>%
    group_by(query) %>%
    mutate(
        time_diff = as.numeric(
            difftime(
                timestamp, 
                lag(timestamp), 
                units = "secs"
            )
        )
    ) %>%
    filter(!is.na(time_diff)) %>%
    ungroup()

summary(time_intervals$time_diff)
```

#### 10. Часто вредоносное программное обеспечение использует DNS канал в качестве канала управления, периодически отправляя запросы на подконтрольный злоумышленникам DNS сервер. По периодическим запросам на один и тот же домен можно выявить скрытый DNS канал. Есть ли такие IP адреса в исследуемом датасете?

Будем фильтровать по стандартному отклонению (для выявления регулярных запросов) и общему количеству запросов для определения подозрительной активаности потенциальных C2-агентов, маскирующихся под DNS-активность

```{r}
dns_log %>%
    filter(!is.na(src_ip), !is.na(query), 
            src_ip != "-", query != "-") %>%
    group_by(src_ip, query) %>%
    mutate(
            time_diff = as.numeric(
                difftime(
                    timestamp, 
                    lag(timestamp), 
                    units = "secs"
                )
            )
        ) %>%
    summarise(
        request_count = n(),
        mean_diff = mean(time_diff, na.rm = TRUE),
        sd_diff   = sd(time_diff, na.rm = TRUE),
    ) %>%
    filter(
        request_count > 35,
        mean_diff < 60,
        sd_diff < 1,
        !is.na(mean_diff)
    ) %>%
    arrange(mean_diff, desc(request_count))
```

Видим 5 доменных записей, к которым просходило множество обращений с большой частотой. Они могли быть использованны злоумышленником для коммуникации С2-агентов или проброса reverse shell

### Обогащение данных

#### 11. Определите местоположение (страну, город) и организацию-провайдера для топ-10 доменов. Для этого можно использовать сторонние сервисы, например http://ip-api.com (API-эндпоинт http://ip-api.com/json)

Обогатим информацию о доменах, используя библиотеки `jsonlite` и `httr`:  

```{r}
get_domain_info <- function(domain) {
    if(is.na(domain) || domain == "") return(NULL)
    api_url <- paste0("http://ip-api.com/json/", domain)

    tryCatch({
        response <- GET(api_url)

        if(status_code(response) == 200) {
            data <- fromJSON(content(response, "text"))
            return(
                tibble(
                    domain = domain,
                    country = ifelse(!is.null(data$country), data$country, NA),
                    countryCode = ifelse(!is.null(data$countryCode), data$countryCode, NA),
                    region = ifelse(!is.null(data$region), data$region, NA),
                    regionName = ifelse(!is.null(data$regionName), data$regionName, NA),
                    city = ifelse(!is.null(data$city), data$city, NA),
                    zip = ifelse(!is.null(data$zip), data$zip, NA),
                    lat = ifelse(!is.null(data$lat), data$lat, NA),
                    lon = ifelse(!is.null(data$lon), data$lon, NA),
                    timezone = ifelse(!is.null(data$timezone), data$timezone, NA),
                    isp = ifelse(!is.null(data$isp), data$isp, NA),
                    org = ifelse(!is.null(data$org), data$org, NA),
                    as = ifelse(!is.null(data$as), data$as, NA),
                    query = ifelse(!is.null(data$query), data$query, NA),
                    stringsAsFactors = FALSE
                )
            )
        } else {
            return(NULL)
        }
    }, error = function(e) {
        return(NULL)
    })
}

bind_rows(
    map(
        top_10_domains_list$query, 
        get_domain_info
    )
)
```

## Вывод

В данной работе мы познакомились с экосистемой `tidyverse` на примере анализа DNS-трафика. Мы также научились коммуникации по протоколу HTTP, используя язык R